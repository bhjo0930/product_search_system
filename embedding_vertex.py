import pandas as pd
from typing import List, Dict
from google.cloud import aiplatform, storage
from vertexai.language_models import TextEmbeddingModel
from vertexai.vision_models import Image, MultiModalEmbeddingModel

# --- âš™ï¸ ì„¤ì • (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •) ---
PROJECT_ID = "ferrous-amphora-466402-i9"
LOCATION = "asia-northeast3"
#us-central1 

# --- í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤ ì •ë³´ ---
TEXT_INDEX_ID = "4887973499278196736"
TEXT_INDEX_ENDPOINT_ID = "1750319157326381056"
DEPLOYED_TEXT_INDEX_ID = f"deployed_{TEXT_INDEX_ID}"

# --- ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ì •ë³´ ---
IMAGE_INDEX_ID = "3398407922525405184"
IMAGE_INDEX_ENDPOINT_ID = "2581233288576237568"
DEPLOYED_IMAGE_INDEX_ID = f"deployed_{IMAGE_INDEX_ID}"

# --- ë°ì´í„° ì •ë³´ ---
PRODUCT_DATA_CSV = "products_data.csv"

# --- ì´ˆê¸°í™” ---
aiplatform.init(project=PROJECT_ID, location=LOCATION)
# storage_clientëŠ” ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
# storage_client = storage.Client(project=PROJECT_ID)
print("âœ… Vertex AI SDKê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ---
text_embedding_model = TextEmbeddingModel.from_pretrained("gemini-embedding-001")
multimodal_embedding_model = MultiModalEmbeddingModel.from_pretrained("multimodalembedding")
print("âœ… í…ìŠ¤íŠ¸ ë° ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

def get_text_from_local_file(local_path: str) -> str:
    """ë¡œì»¬ íŒŒì¼ ê²½ë¡œì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì½ì–´ì˜µë‹ˆë‹¤."""
    try:
        with open(local_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {local_path}")
        return ""
    except Exception as e:
        print(f"ë¡œì»¬ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {local_path}, ì˜¤ë¥˜: {e}")
        return ""

def get_text_embedding(text: str) -> List[float]:
    """í…ìŠ¤íŠ¸ë¡œë¶€í„° ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤ (3,072ì°¨ì›)."""
    embeddings = text_embedding_model.get_embeddings([text])
    return embeddings[0].values

def get_image_embedding(local_image_path: str) -> List[float]:
    """ë¡œì»¬ ì´ë¯¸ì§€ë¡œë¶€í„° ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤ (1,408ì°¨ì›)."""
    # Image.load_from_fileì€ ë¡œì»¬ ê²½ë¡œë„ ì§€ì›í•©ë‹ˆë‹¤.
    image = Image.load_from_file(local_image_path)
    embeddings = multimodal_embedding_model.get_embeddings(
        image=image,
        dimension=1408
    )
    return embeddings.image_embedding

def process_and_upsert_products(csv_file_path: str):
    """ìƒí’ˆ ì •ë³´ë¥¼ ì½ê³ , ê°ê°ì˜ ì¸ë±ìŠ¤ì— ì„ë² ë”©ì„ ì—…ì„œíŠ¸í•©ë‹ˆë‹¤."""
    try:
        products_df = pd.read_csv(csv_file_path)
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {csv_file_path}")
        return
        
    text_embeddings_to_upsert = []
    image_embeddings_to_upsert = []

    print(f"\nğŸš€ ì´ {len(products_df)}ê°œì˜ ìƒí’ˆ ì •ë³´ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    for _, row in products_df.iterrows():
        product_id = str(row['product_id'])
        # CSVì—ì„œ ë¡œì»¬ ê²½ë¡œë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
        text_path = row['text_file_local_path']
        image_path = row['image_file_local_path']

        print(f"  - ìƒí’ˆ ID '{product_id}' ì²˜ë¦¬ ì¤‘...")
        try:
            # í…ìŠ¤íŠ¸ ì²˜ë¦¬
            product_text = get_text_from_local_file(text_path)
            if product_text:
                text_vector = get_text_embedding(product_text)
                text_embeddings_to_upsert.append({"id": product_id, "embedding": text_vector})

            # ì´ë¯¸ì§€ ì²˜ë¦¬
            image_vector = get_image_embedding(image_path)
            image_embeddings_to_upsert.append({"id": product_id, "embedding": image_vector})

        except Exception as e:
            print(f"    - â—ï¸ ì˜¤ë¥˜ ë°œìƒ: {product_id} ìƒí’ˆ ì²˜ë¦¬ ì‹¤íŒ¨ - {e}")

    # í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤ì— ì—…ì„œíŠ¸
    if text_embeddings_to_upsert:
        print(f"\nğŸ’¾ í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤ì— {len(text_embeddings_to_upsert)}ê°œ ì—…ì„œíŠ¸ ì¤‘...")
        text_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(index_endpoint_name=TEXT_INDEX_ENDPOINT_ID)
        text_index_endpoint.upsert_datapoints(datapoints=text_embeddings_to_upsert, deployed_index_id=DEPLOYED_TEXT_INDEX_ID)
        print("âœ… í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤ ì—…ì„œíŠ¸ ì™„ë£Œ.")

    # ì´ë¯¸ì§€ ì¸ë±ìŠ¤ì— ì—…ì„œíŠ¸
    if image_embeddings_to_upsert:
        print(f"\nğŸ’¾ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ì— {len(image_embeddings_to_upsert)}ê°œ ì—…ì„œíŠ¸ ì¤‘...")
        image_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(index_endpoint_name=IMAGE_INDEX_ENDPOINT_ID)
        image_index_endpoint.upsert_datapoints(datapoints=image_embeddings_to_upsert, deployed_index_id=DEPLOYED_IMAGE_INDEX_ID)
        print("âœ… ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ì—…ì„œíŠ¸ ì™„ë£Œ.")

def reciprocal_rank_fusion(search_results: List[List[aiplatform.matching_engine.matching_engine_index_endpoint.MatchNeighbor]], k: int = 60) -> Dict[str, float]:
    """Reciprocal Rank Fusion (RRF)ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìœµí•©í•©ë‹ˆë‹¤."""
    fused_scores = {}
    for result_list in search_results:
        for rank, match in enumerate(result_list):
            doc_id = match.id
            if doc_id not in fused_scores:
                fused_scores[doc_id] = 0
            fused_scores[doc_id] += 1 / (k + rank + 1)

    reranked_results = {
        id: score
        for id, score in sorted(fused_scores.items(), key=lambda item: item[1], reverse=True)
    }
    return reranked_results

def find_similar_products_with_fusion(query_text: str, query_image_local_path: str, num_neighbors: int = 10):
    """ë‘ ì¸ë±ìŠ¤ì—ì„œ ë³‘ë ¬ ê²€ìƒ‰ í›„ RRFë¡œ ê²°ê³¼ë¥¼ ìœµí•©í•©ë‹ˆë‹¤."""
    print(f"\nğŸ” ì¿¼ë¦¬ë¡œ ìœ ì‚¬ ìƒí’ˆ ê²€ìƒ‰ (Fusion ë°©ì‹)...")

    # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_text_embedding = get_text_embedding(query_text)
    query_image_embedding = get_image_embedding(query_image_local_path)

    # 2. ê° ì¸ë±ìŠ¤ì—ì„œ ë³‘ë ¬ ê²€ìƒ‰
    text_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(index_endpoint_name=TEXT_INDEX_ENDPOINT_ID)
    image_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(index_endpoint_name=IMAGE_INDEX_ENDPOINT_ID)

    print("  - í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤ ê²€ìƒ‰ ì¤‘...")
    text_search_results = text_index_endpoint.find_neighbors(
        deployed_index_id=DEPLOYED_TEXT_INDEX_ID,
        queries=[query_text_embedding],
        num_neighbors=num_neighbors,
    )

    print("  - ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ê²€ìƒ‰ ì¤‘...")
    image_search_results = image_index_endpoint.find_neighbors(
        deployed_index_id=DEPLOYED_IMAGE_INDEX_ID,
        queries=[query_image_embedding],
        num_neighbors=num_neighbors,
    )

    # 3. RRFë¡œ ê²°ê³¼ ìœµí•©
    print("  - ê²€ìƒ‰ ê²°ê³¼ ìœµí•© (RRF) ì¤‘...")
    fused_results = reciprocal_rank_fusion([text_search_results[0], image_search_results[0]])

    # 4. ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n--- ğŸ“Š ìµœì¢… ìœµí•© ê²€ìƒ‰ ê²°ê³¼ ---")
    if not fused_results:
        print("ìœ ì‚¬í•œ ìƒí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return
    
    for i, (doc_id, score) in enumerate(list(fused_results.items())[:num_neighbors]):
        print(f"  - ìµœì¢… ìˆœìœ„ {i+1}: ìƒí’ˆ ID: {doc_id}, RRF ì ìˆ˜: {score:.6f}")


if __name__ == "__main__":
    # --- ì‹¤í–‰ ë‹¨ê³„ ---

    # 1. ìƒí’ˆ ë°ì´í„° ì²˜ë¦¬ ë° ê° Matching Engine ì¸ë±ìŠ¤ì— ì €ì¥
    #    (ìµœì´ˆ 1íšŒ ë˜ëŠ” ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œ ì‹¤í–‰)
    process_and_upsert_products(PRODUCT_DATA_CSV)

    # 2. íŠ¹ì • ì¿¼ë¦¬ë¡œ ìœ ì‚¬ ìƒí’ˆ ê²€ìƒ‰ (ìœµí•© ë°©ì‹)
    #    (ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©ë  ê¸°ëŠ¥)
    search_query_text = "ì—¬ë¦„ì— ì‹œì›í•˜ê²Œ ì…ì„ ìˆ˜ ìˆëŠ” íŒŒë€ìƒ‰ ë°˜íŒ” í‹°ì…”ì¸ "
    # ê²€ìƒ‰ì— ì‚¬ìš©í•  ì´ë¯¸ì§€ì˜ ë¡œì»¬ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
    search_query_image = "./query_data/query_tshirt.jpg" 

    find_similar_products_with_fusion(
        query_text=search_query_text,
        query_image_local_path=search_query_image,
        num_neighbors=5 # ìµœì¢…ì ìœ¼ë¡œ ë³´ì—¬ì¤„ ìƒìœ„ 5ê°œ ìƒí’ˆ
    )
